{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943 1682\n",
      "(95000, 4)\n",
      "(5000, 4)\n",
      "(943, 943)\n",
      "(1682, 1682)\n",
      "User-based CF RMSE: 2.763148978623458\n",
      "User-based CF RMSE: 2.732867708896345\n",
      "Item-based CF RMSE: 3.002423579565451\n",
      "User-based CRR CF RMSE: 2.7458228780557237\n",
      "Item-based CRR CF RMSE: 3.0764570775868783\n",
      "user_pred\n",
      "[[3.79010024 1.87940521 1.47018281 ... 0.         0.07344591 0.08130924]\n",
      " [2.12586135 0.         0.33903937 ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.06027481 0.         0.        ]\n",
      " ...\n",
      " [3.76242197 0.         0.42610321 ... 0.         0.         0.        ]\n",
      " [2.13469403 0.7544691  0.14160944 ... 0.         0.         0.        ]\n",
      " [3.13629225 2.3165088  1.54567795 ... 0.         0.07197124 0.0703887 ]]\n",
      "(943, 1682)\n",
      "Top-k User-based CF RMSE: 2.3201094526589223\n",
      "['Star Wars (1977)', 'Raiders of the Lost Ark (1981)', 'Empire Strikes Back, The (1980)', 'Silence of the Lambs, The (1991)', 'Forrest Gump (1994)']\n",
      "Item-based CF RMSE: 2.268194993696417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\" def pearson_correlation(user1, user2):\\n    df1= dataset.loc[(dataset.userID == user1 ),'movieID'].tolist()\\n    df2= dataset.loc[(dataset.userID == user2 ),'movieID'].tolist()\\n\\n    print(len(df1))\\n    print(len(df2))\\n\\n    both_rated = { }\\n    for i in df1:\\n        if i in df2:\\n            both_rated[i] = 1       \\n    \\n    number_of_rating = len(both_rated)\\n    print(df1)\\n    print(df2)\\n    print(number_of_rating)\\n\\n    if number_of_rating == 0:\\n        return 0 \\n    # Add up all the preferences of each user\\n    #print(user1_preferences_sum = sum(df1[item] for item in both_rated))\\n    #print(user2_preferences_sum = sum(df2[item] for item in both_rated))\\n\\n    # Sum up the squares of preferences of each user\\n    user1_square_preferences_sum = sum([pow(df1[item],2) for item in both_rated])\\n    user2_square_preferences_sum = sum([pow(df2[item],2) for item in both_rated])\\n\\n    # Sum up the product value of both preferences for each item\\n    product_sum_of_both_users = sum( [dataset[person1][item] * dataset[person2][item] for item in both_rated] )\\n \\n    # Calculate the pearson score\\n    numerator_value = product_sum_of_both_users - ( user1_preferences_sum*user2_preferences_sum/number_of_ratings )\\n    denominator_value = sqrt( (user1_square_preferences_sum - pow(user1_preferences_sum,2)/number_of_ratings) * (user2_square_preferences_sum - pow(user2_preferences_sum,2)/number_of_ratings) )\\n    if denominator_value == 0:\\n        return 0\\n    else:\\n        r = numerator_value/denominator_value\\n        return r\\n\\nprint( pearson_correlation(1, 2))\\n \\n\\npearson_correlation(4, 2)\\n\\n\\n# check_both_rated(1, 2) \""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import sqrt\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# column headers for the dataset\n",
    "data_cols = ['userID', 'movieID', 'rating', 'timestamp']\n",
    "item_cols = ['movieID', 'movie_title', 'release_date', 'video_release_date','IMDb_URL', 'unknown', 'Action', 'Adventure', 'Animation', 'Childrens', 'Comedy', 'Crime', 'Documentary', 'Drama','Fantasy','Film-Noir','Horror', 'Musical','Mystery','Romance ','Sci-Fi','Thriller', 'War', 'Western']\n",
    "user_cols = ['userID', 'age', 'gender', 'occupation', 'zip_code']\n",
    "\n",
    "# importing the data files onto dataframes\n",
    "data = pd.read_csv('./ml-100k/u.data', sep='\\t', names=data_cols, encoding='latin-1')\n",
    "item = pd.read_csv('./ml-100k/u.item', sep='|', names=item_cols, encoding='latin-1')\n",
    "users = pd.read_csv('./ml-100k/u.user', sep='|', names=user_cols, encoding='latin-1')\n",
    "\n",
    "item['movieID'] = item['movieID'].apply(pd.to_numeric)\n",
    "\n",
    "# merging 3 data sets\n",
    "dataset = pd.merge(pd.merge(item, data), users)\n",
    "\n",
    "n_users = data.userID.unique().shape[0]\n",
    "n_movies = data.movieID.unique().shape[0]\n",
    "\n",
    "print(n_users, n_movies)\n",
    "#########################################################################\n",
    "# splitting data to testing and training data\n",
    "########################################################################\n",
    "train_data, test_data = train_test_split(data, test_size=0.05, random_state=42)\n",
    "print(\"1\")\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "train_data_matrix = np.zeros((n_users, n_movies))\n",
    "for line in train_data.itertuples():\n",
    "    # print(line)\n",
    "    train_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    # -1 bcoz there is no user or movie with id 0\n",
    "\n",
    "test_data_matrix = np.zeros((n_users, n_movies))\n",
    "for line in test_data.itertuples():\n",
    "    # print(line)\n",
    "    test_data_matrix[line[1]-1, line[2]-1] = line[3]\n",
    "    # -1 bcoz there is no user or movie with id 0\n",
    "\n",
    "# print(train_data_matrix)\n",
    "#########################################################################\n",
    "# using pairwise distance from from sklearn\n",
    "#########################################################################\n",
    "user_similarity = 1 - pairwise_distances(train_data_matrix, metric='cosine')\n",
    "movie_similarity = 1 - pairwise_distances(train_data_matrix.T, metric='cosine')\n",
    "# print(user_similarity)\n",
    "#print(movie_similarity)\n",
    "user_similarity_crr =1 - pairwise_distances(train_data_matrix, metric='correlation')\n",
    "movie_similarity_crr = 1 - pairwise_distances(train_data_matrix.T, metric='correlation')\n",
    "movie_similarity_crr[np.isnan(movie_similarity_crr)] = 0\n",
    "print(user_similarity_crr.shape)\n",
    "print(movie_similarity_crr.shape)\n",
    "\n",
    "#########################################################################\n",
    "# predicting the ratings\n",
    "#########################################################################\n",
    "def predict ( ratings, similarity, type='user' ):\n",
    "\n",
    "    if type == 'user':\n",
    "        mean_user_rating = ratings.mean(axis=1)\n",
    "        # here axis = 1 means along the row. Default is axis = 0 which means along the column\n",
    "        #You use np.newaxis so that mean_user_rating has same format as ratings         \n",
    "        #print(ratings.shape)  (943, 1682)\n",
    "        #print(mean_user_rating[:, np.newaxis].shape) (943,1)\n",
    "\n",
    "\n",
    "        ratings_diff = (ratings - mean_user_rating[:, np.newaxis])\n",
    "        pred = mean_user_rating[:, np.newaxis] + similarity.dot(ratings_diff) / np.array([np.abs(similarity).sum(axis=1)]).T\n",
    "        #print(pred.shape)\n",
    "    elif type == 'item':\n",
    "        pred = ratings.dot(similarity) / np.array([np.abs(similarity).sum(axis=1)])\n",
    "        #print(pred.shape)\n",
    "    return pred\n",
    "\n",
    "movie_prediction = predict (train_data_matrix, movie_similarity, type='item')\n",
    "user_prediction = predict(train_data_matrix, user_similarity, type='user')\n",
    "\n",
    "\n",
    "movie_prediction_crr = predict(train_data_matrix, movie_similarity_crr, type='item')\n",
    "user_prediction_crr = predict(train_data_matrix, user_similarity_crr, type='user')\n",
    "\n",
    "# print(movie_prediction[ :2])\n",
    "# print(user_prediction)\n",
    "# print(movie_prediction_crr[ :2])\n",
    "\n",
    "#########################################################################\n",
    "# Rmse\n",
    "#########################################################################\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = prediction[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = ground_truth[ground_truth.nonzero()].flatten()\n",
    "    return sqrt(mean_squared_error(prediction, ground_truth))\n",
    "\n",
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, test_data_matrix)))\n",
    "print ('User-based CF RMSE: ' + str(rmse(user_prediction, train_data_matrix)))\n",
    "print ('Item-based CF RMSE: ' + str(rmse(movie_prediction, test_data_matrix)))\n",
    "\n",
    "print ('User-based CRR CF RMSE: ' + str(rmse(user_prediction_crr, test_data_matrix)))\n",
    "print ('Item-based CRR CF RMSE: ' + str(rmse(movie_prediction_crr, test_data_matrix)))\n",
    "\n",
    "\n",
    "def predict_topk(ratings, similarity, kind='user', k=50):\n",
    "    pred = np.zeros(ratings.shape)\n",
    "    if kind == 'user':\n",
    "        for i in range(ratings.shape[0]):\n",
    "            # [:total no of elements required*-1 : -1 for descending order]\n",
    "            top_k_users = [np.argsort(similarity[:,i])[:-k-1:-1]]\n",
    "            for j in range(ratings.shape[1]):\n",
    "                pred[i, j] = similarity[i, :][top_k_users].dot(ratings[:, j][top_k_users]) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[i, :][top_k_users]))\n",
    "    if kind == 'item':\n",
    "        for j in range(ratings.shape[1]):\n",
    "            top_k_items = [np.argsort(similarity[:,j])[:-k-1:-1]]\n",
    "            for i in range(ratings.shape[0]):\n",
    "                pred[i, j] = similarity[j, :][top_k_items].dot(ratings[i, :][top_k_items].T) \n",
    "                pred[i, j] /= np.sum(np.abs(similarity[j, :][top_k_items]))        \n",
    "    \n",
    "    return pred\n",
    "\n",
    "pred = predict_topk(train_data_matrix, user_similarity, kind='user', k=40)\n",
    "print(\"user_pred\")\n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "print ('Top-k User-based CF RMSE: ' + str(rmse(pred, test_data_matrix)))\n",
    "'''\n",
    "pred = predict_topk(train_data_matrix, movie_similarity_crr, kind='item', k=50)\n",
    "print(\"item pred\")\n",
    "print(pred)\n",
    "print(pred.shape)\n",
    "print ('Top-k Item-based CF RMSE: ' + str(rmse(pred, test_data_matrix)))\n",
    "'''\n",
    "\n",
    "#########################################################################\n",
    "# Recommending movies to a user with idx\n",
    "######################################################################### \n",
    "idx_to_movie = {}\n",
    "with open('./ml-100k/u.item', 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        info = line.split('|')\n",
    "        idx_to_movie[int(info[0])-1] = info[1]\n",
    "\n",
    "def top_k_movies(similarity, mapper, movie_idx, k=5):\n",
    "    return [mapper[x] for x in np.argsort(similarity[movie_idx,:])[:-k-1:-1]]\n",
    "\n",
    "idx = 11\n",
    "movies = top_k_movies(pred, idx_to_movie, idx)\n",
    "# posters = tuple(Image(url=get_poster(movie, base_url)) for movie in movies)\n",
    "print(movies[:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#########################################################################\n",
    "# Model based approach SVD Singular Value Decomposition\n",
    "#########################################################################\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "#get SVD components from train matrix. Choose k.\n",
    "u, s, vt = svds(pred, k = 20)\n",
    "s_diag_matrix=np.diag(s)\n",
    "X_pred = np.dot(np.dot(u, s_diag_matrix), vt)\n",
    "print ('Item-based CF RMSE: ' + str(rmse(X_pred, test_data_matrix)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "def recommend_movies(predictions_df, userID, movies_df, original_ratings_df, num_recommendations=5):\n",
    "    \n",
    "    # Get and sort the user's predictions\n",
    "    user_row_number = userID - 1 # userID starts at 1, not 0\n",
    "    predictions_df = pd.DataFrame(predictions_df)\n",
    "    sorted_user_predictions = predictions_df.iloc[user_row_number].sort_values(ascending=False)\n",
    "    \n",
    "    # Get the user's data and merge in the movie information.\n",
    "    user_data = original_ratings_df[original_ratings_df.userID == (userID)]\n",
    "    user_full = (user_data.merge(movies_df, how = 'left', left_on = 'movieID', right_on = 'movieID').\n",
    "                     sort_values(['rating'], ascending=False)\n",
    "                 )\n",
    "\n",
    "    print ('User {0} has already rated {1} movies.'.format(userID, user_full.shape[0]))\n",
    "    print ('Recommending the highest {0} predicted ratings movies not already rated.'.format(num_recommendations))\n",
    "    \n",
    "    # Recommend the highest predicted rating movies that the user hasn't seen yet.\n",
    "    recommendations = (movies_df[~movies_df['movieID'].isin(user_full['movieID'])].\n",
    "         merge(pd.DataFrame(sorted_user_predictions).reset_index(), how = 'left',\n",
    "               left_on = 'movieID',\n",
    "               right_on = 'movieID').\n",
    "         rename(columns = {user_row_number: 'Predictions'}).\n",
    "         sort_values('Predictions', ascending = False).\n",
    "                       iloc[:num_recommendations, :-1]\n",
    "                      )\n",
    "\n",
    "    return user_full, recommendations\n",
    "\n",
    "predictions = recommend_movies(pred, 837, item, data, 10)\n",
    "\n",
    "print(predictions[:])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "''' def pearson_correlation(user1, user2):\n",
    "    df1= dataset.loc[(dataset.userID == user1 ),'movieID'].tolist()\n",
    "    df2= dataset.loc[(dataset.userID == user2 ),'movieID'].tolist()\n",
    "\n",
    "    print(len(df1))\n",
    "    print(len(df2))\n",
    "\n",
    "    both_rated = { }\n",
    "    for i in df1:\n",
    "        if i in df2:\n",
    "            both_rated[i] = 1       \n",
    "    \n",
    "    number_of_rating = len(both_rated)\n",
    "    print(df1)\n",
    "    print(df2)\n",
    "    print(number_of_rating)\n",
    "\n",
    "    if number_of_rating == 0:\n",
    "        return 0 \n",
    "    # Add up all the preferences of each user\n",
    "    #print(user1_preferences_sum = sum(df1[item] for item in both_rated))\n",
    "    #print(user2_preferences_sum = sum(df2[item] for item in both_rated))\n",
    "\n",
    "    # Sum up the squares of preferences of each user\n",
    "    user1_square_preferences_sum = sum([pow(df1[item],2) for item in both_rated])\n",
    "    user2_square_preferences_sum = sum([pow(df2[item],2) for item in both_rated])\n",
    "\n",
    "    # Sum up the product value of both preferences for each item\n",
    "    product_sum_of_both_users = sum( [dataset[person1][item] * dataset[person2][item] for item in both_rated] )\n",
    " \n",
    "    # Calculate the pearson score\n",
    "    numerator_value = product_sum_of_both_users - ( user1_preferences_sum*user2_preferences_sum/number_of_ratings )\n",
    "    denominator_value = sqrt( (user1_square_preferences_sum - pow(user1_preferences_sum,2)/number_of_ratings) * (user2_square_preferences_sum - pow(user2_preferences_sum,2)/number_of_ratings) )\n",
    "    if denominator_value == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        r = numerator_value/denominator_value\n",
    "        return r\n",
    "\n",
    "print( pearson_correlation(1, 2))\n",
    " \n",
    "\n",
    "pearson_correlation(4, 2)\n",
    "\n",
    "\n",
    "# check_both_rated(1, 2) '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
